{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install transformers==3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pip install mxnet\n",
    "# pip install gluonnlp pandas tqdm\n",
    "# pip install sentencepiece\n",
    "# pip install transformers\n",
    "# pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install cuda==10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2AGpK7urid1b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "import urllib.request\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import gluonnlp as nlp\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 쇼핑 리뷰 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Nh7NecakK-3",
    "outputId": "5468ef38-a93d-4bcc-dd79-acdead552d6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings_total.txt', <http.client.HTTPMessage at 0x7f0c704cbf70>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt\", filename=\"ratings_total.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6dCYGaa7kkVa",
    "outputId": "a077a8d2-dbac-4914-91ce-dde057ebbc0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 리뷰 개수 : 200000\n"
     ]
    }
   ],
   "source": [
    "# 열 제목 설정\n",
    "total_data = pd.read_table('ratings_total.txt', names=['ratings', 'reviews'])\n",
    "print('전체 리뷰 개수 :',len(total_data)) # 전체 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "R5GgI3RDknDE",
    "outputId": "fe621fd4-83b8-4b0c-9c9f-1db47fa0d7b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>배공빠르고 굿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ratings                                            reviews\n",
       "0        5                                            배공빠르고 굿\n",
       "1        2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
       "2        5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...\n",
       "3        2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...\n",
       "4        5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 긍부정 판단을 위한 라벨 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "cZZuNukmkpuP",
    "outputId": "33d1e5a6-7d13-439b-badc-d47e0cc4d5a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>배공빠르고 굿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ratings                                            reviews  label\n",
       "0        5                                            배공빠르고 굿      1\n",
       "1        2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고      0\n",
       "2        5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...      1\n",
       "3        2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...      0\n",
       "4        5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data['label'] = np.select([total_data.ratings > 3], [1], default=0)\n",
    "total_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-Ljct3Rk55K",
    "outputId": "8b5eb037-8811-4bc2-8317-ac4013cdd018"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 199908, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data['ratings'].nunique(), total_data['reviews'].nunique(), total_data['label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ub4ztwdKk8AN",
    "outputId": "9bef1685-2cc5-48c8-befd-a50566c5b9d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 199908\n"
     ]
    }
   ],
   "source": [
    "# reviews 열에서 중복인 내용이 있다면 중복 제거\n",
    "total_data.drop_duplicates(subset=['reviews'], inplace=True)\n",
    "print('총 샘플의 수 :',len(total_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KtUzXmtwk-Bx",
    "outputId": "a1b24b8f-1215-4411-be82-46449b3cac51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(total_data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTT 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Cl4uddajlAzc"
   },
   "outputs": [],
   "source": [
    "test_data1 = pd.read_csv('./웨이브전처리.csv')\n",
    "test_data2 = pd.read_csv('./티빙전처리.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JnH4-JsvmjUh"
   },
   "outputs": [],
   "source": [
    "del test_data1['Unnamed: 0']\n",
    "del test_data2['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_data1['date']\n",
    "del test_data1['comment']\n",
    "del test_data1['nouns']\n",
    "test_data1.columns = ['ratings', 'reviews', 'label']\n",
    "\n",
    "del test_data2['date']\n",
    "del test_data2['comment']\n",
    "del test_data2['nouns']\n",
    "test_data2.columns = ['ratings', 'reviews', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([test_data1,test_data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>오류 굉장히 많고 개별구매 영화 개많아요 가뜩이나 비싼데 돈을 얼마나 더받으려고 넷...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>한번 더팅기면 회사 소각시켜도되나요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>프리미엄 원짜리 후기입니다 일단 사지 마세요 재미있는 영화는 거의다 막아서 프리미엄...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>오늘 앱이 죙일 안열리네요 자주 이러면 곤란한데 먼일이데요 언넝 조치를 취해주셔요 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ㅡㄴㄴㄱ 즈 ㄱㄴ 그냥 ㄴㄴ ㄴ 드ㅡㅡㅜ ㅣ두 ㄴㄴㅗ트 ㄴ ㅡㅡ ㅡㅡ윤석원드ㅡ ㄴ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15920</th>\n",
       "      <td>5</td>\n",
       "      <td>디자이어 아주 잘됩니다 더좋아지겠죠 볼만한건 유료라지만 유료라도이정도면 볼만한듯</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15921</th>\n",
       "      <td>1</td>\n",
       "      <td>세상에공짜는 없다 볼만한건전부 유료다 바로삭제</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15922</th>\n",
       "      <td>1</td>\n",
       "      <td>갤 인데 오류쩔어요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15923</th>\n",
       "      <td>5</td>\n",
       "      <td>채널수와 화질에서는 와는 비교가 안되는군요 티빙짱입니다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15924</th>\n",
       "      <td>5</td>\n",
       "      <td>우와 이론 멋진 앱이 있다니 띠용</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43317 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ratings                                            reviews  label\n",
       "0            1  오류 굉장히 많고 개별구매 영화 개많아요 가뜩이나 비싼데 돈을 얼마나 더받으려고 넷...      0\n",
       "1            1                                한번 더팅기면 회사 소각시켜도되나요      0\n",
       "2            1  프리미엄 원짜리 후기입니다 일단 사지 마세요 재미있는 영화는 거의다 막아서 프리미엄...      0\n",
       "3            3  오늘 앱이 죙일 안열리네요 자주 이러면 곤란한데 먼일이데요 언넝 조치를 취해주셔요 ...      0\n",
       "4            5  ㅡㄴㄴㄱ 즈 ㄱㄴ 그냥 ㄴㄴ ㄴ 드ㅡㅡㅜ ㅣ두 ㄴㄴㅗ트 ㄴ ㅡㅡ ㅡㅡ윤석원드ㅡ ㄴ ...      1\n",
       "...        ...                                                ...    ...\n",
       "15920        5       디자이어 아주 잘됩니다 더좋아지겠죠 볼만한건 유료라지만 유료라도이정도면 볼만한듯      1\n",
       "15921        1                          세상에공짜는 없다 볼만한건전부 유료다 바로삭제      0\n",
       "15922        1                                         갤 인데 오류쩔어요      0\n",
       "15923        5                     채널수와 화질에서는 와는 비교가 안되는군요 티빙짱입니다      1\n",
       "15924        5                                 우와 이론 멋진 앱이 있다니 띠용      1\n",
       "\n",
       "[43317 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "Ke-GPsbKlgrc",
    "outputId": "a8fa1ded-ae87-4b98-8472-fcc03bee3975",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>오류 굉장히 많고 개별구매 영화 개많아요 가뜩이나 비싼데 돈을 얼마나 더받으려고 넷...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>한번 더팅기면 회사 소각시켜도되나요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>프리미엄 원짜리 후기입니다 일단 사지 마세요 재미있는 영화는 거의다 막아서 프리미엄...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>오늘 앱이 죙일 안열리네요 자주 이러면 곤란한데 먼일이데요 언넝 조치를 취해주셔요 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ㅡㄴㄴㄱ 즈 ㄱㄴ 그냥 ㄴㄴ ㄴ 드ㅡㅡㅜ ㅣ두 ㄴㄴㅗ트 ㄴ ㅡㅡ ㅡㅡ윤석원드ㅡ ㄴ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43312</th>\n",
       "      <td>5</td>\n",
       "      <td>디자이어 아주 잘됩니다 더좋아지겠죠 볼만한건 유료라지만 유료라도이정도면 볼만한듯</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43313</th>\n",
       "      <td>1</td>\n",
       "      <td>세상에공짜는 없다 볼만한건전부 유료다 바로삭제</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43314</th>\n",
       "      <td>1</td>\n",
       "      <td>갤 인데 오류쩔어요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43315</th>\n",
       "      <td>5</td>\n",
       "      <td>채널수와 화질에서는 와는 비교가 안되는군요 티빙짱입니다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43316</th>\n",
       "      <td>5</td>\n",
       "      <td>우와 이론 멋진 앱이 있다니 띠용</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43317 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ratings                                            reviews  label\n",
       "0            1  오류 굉장히 많고 개별구매 영화 개많아요 가뜩이나 비싼데 돈을 얼마나 더받으려고 넷...      0\n",
       "1            1                                한번 더팅기면 회사 소각시켜도되나요      0\n",
       "2            1  프리미엄 원짜리 후기입니다 일단 사지 마세요 재미있는 영화는 거의다 막아서 프리미엄...      0\n",
       "3            3  오늘 앱이 죙일 안열리네요 자주 이러면 곤란한데 먼일이데요 언넝 조치를 취해주셔요 ...      0\n",
       "4            5  ㅡㄴㄴㄱ 즈 ㄱㄴ 그냥 ㄴㄴ ㄴ 드ㅡㅡㅜ ㅣ두 ㄴㄴㅗ트 ㄴ ㅡㅡ ㅡㅡ윤석원드ㅡ ㄴ ...      1\n",
       "...        ...                                                ...    ...\n",
       "43312        5       디자이어 아주 잘됩니다 더좋아지겠죠 볼만한건 유료라지만 유료라도이정도면 볼만한듯      1\n",
       "43313        1                          세상에공짜는 없다 볼만한건전부 유료다 바로삭제      0\n",
       "43314        1                                         갤 인데 오류쩔어요      0\n",
       "43315        5                     채널수와 화질에서는 와는 비교가 안되는군요 티빙짱입니다      1\n",
       "43316        5                                 우와 이론 멋진 앱이 있다니 띠용      1\n",
       "\n",
       "[43317 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스 리셋\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTT 데이터와 쇼핑 데이터 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>배공빠르고 굿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43312</th>\n",
       "      <td>5</td>\n",
       "      <td>디자이어 아주 잘됩니다 더좋아지겠죠 볼만한건 유료라지만 유료라도이정도면 볼만한듯</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43313</th>\n",
       "      <td>1</td>\n",
       "      <td>세상에공짜는 없다 볼만한건전부 유료다 바로삭제</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43314</th>\n",
       "      <td>1</td>\n",
       "      <td>갤 인데 오류쩔어요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43315</th>\n",
       "      <td>5</td>\n",
       "      <td>채널수와 화질에서는 와는 비교가 안되는군요 티빙짱입니다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43316</th>\n",
       "      <td>5</td>\n",
       "      <td>우와 이론 멋진 앱이 있다니 띠용</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243225 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ratings                                            reviews  label\n",
       "0            5                                            배공빠르고 굿      1\n",
       "1            2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고      0\n",
       "2            5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...      1\n",
       "3            2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...      0\n",
       "4            5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ      1\n",
       "...        ...                                                ...    ...\n",
       "43312        5       디자이어 아주 잘됩니다 더좋아지겠죠 볼만한건 유료라지만 유료라도이정도면 볼만한듯      1\n",
       "43313        1                          세상에공짜는 없다 볼만한건전부 유료다 바로삭제      0\n",
       "43314        1                                         갤 인데 오류쩔어요      0\n",
       "43315        5                     채널수와 화질에서는 와는 비교가 안되는군요 티빙짱입니다      1\n",
       "43316        5                                 우와 이론 멋진 앱이 있다니 띠용      1\n",
       "\n",
       "[243225 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OTT와 쇼핑 리뷰 데이터 concat\n",
    "total_data = pd.concat([total_data,test_data])\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>배공빠르고 굿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243220</th>\n",
       "      <td>5</td>\n",
       "      <td>디자이어 아주 잘됩니다 더좋아지겠죠 볼만한건 유료라지만 유료라도이정도면 볼만한듯</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243221</th>\n",
       "      <td>1</td>\n",
       "      <td>세상에공짜는 없다 볼만한건전부 유료다 바로삭제</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243222</th>\n",
       "      <td>1</td>\n",
       "      <td>갤 인데 오류쩔어요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243223</th>\n",
       "      <td>5</td>\n",
       "      <td>채널수와 화질에서는 와는 비교가 안되는군요 티빙짱입니다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243224</th>\n",
       "      <td>5</td>\n",
       "      <td>우와 이론 멋진 앱이 있다니 띠용</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243225 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ratings                                            reviews  label\n",
       "0             5                                            배공빠르고 굿      1\n",
       "1             2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고      0\n",
       "2             5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...      1\n",
       "3             2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...      0\n",
       "4             5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ      1\n",
       "...         ...                                                ...    ...\n",
       "243220        5       디자이어 아주 잘됩니다 더좋아지겠죠 볼만한건 유료라지만 유료라도이정도면 볼만한듯      1\n",
       "243221        1                          세상에공짜는 없다 볼만한건전부 유료다 바로삭제      0\n",
       "243222        1                                         갤 인데 오류쩔어요      0\n",
       "243223        5                     채널수와 화질에서는 와는 비교가 안되는군요 티빙짱입니다      1\n",
       "243224        5                                 우와 이론 멋진 앱이 있다니 띠용      1\n",
       "\n",
       "[243225 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스 리셋\n",
    "total_data.reset_index(drop=True, inplace=True)\n",
    "total_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### total_data 확인 및 null 값 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_data['label'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label   count\n",
      "0      0  132593\n",
      "1      1  110632\n"
     ]
    }
   ],
   "source": [
    "print(total_data.groupby('label').size().reset_index(name = 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Null 값 확인\n",
    "print(total_data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings      0\n",
      "reviews    137\n",
      "label        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(total_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "total_data = total_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print(total_data.isnull().values.any()) # Null 값이 존재하는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train data와 test data로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "INNQQT2Tl3jw",
    "outputId": "24bfe698-5b79-4c9b-f7f3-40b95f77e2b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 리뷰의 개수 : 182316\n",
      "테스트용 리뷰의 개수 : 60772\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(total_data, test_size = 0.25, random_state = 42)\n",
    "print('훈련용 리뷰의 개수 :', len(train_data))\n",
    "print('테스트용 리뷰의 개수 :', len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynjY7OD_nldC"
   },
   "source": [
    "### 레이블 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "0v3SS2wfm3yi",
    "outputId": "a482e472-9722-499c-8edd-7cf1bbdc015d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['label'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5wJIcDKm5kv",
    "outputId": "e8511c5e-8137-4a13-8a23-555bfe20c870",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  count\n",
      "0      0  99318\n",
      "1      1  82998\n"
     ]
    }
   ],
   "source": [
    "print(train_data.groupby('label').size().reset_index(name = 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Null 값 확인\n",
    "print(train_data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리 - 훈련셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29741     굿 괜찮네요굿배송도빠르게왔네요저렴한지는 잘모르겠지만효과가좋으면괜찮겠네요효과좋겠죠아무...\n",
       "169589                            재구매 마트보다 고기가 좋아요 믿고 구매합니다\n",
       "227594               약관동의 창이 아무 내용도 없는 하얀화면인데 어떻게 로그인 하라는건지\n",
       "923                                     조금더 작은 사이즈 있으면 좋겠어요\n",
       "105731                                      처음 구매했는데 좋으네요^^\n",
       "194065                            잘 먹고 있습니다. 꼼꼼한 포장 감사드립니다.\n",
       "225861    아직 계약이 안된건가여 요즘 드라마 대세가 인데 넘 아쉽습니다 꼭 나오게 좀 해주셔...\n",
       "59882                            민트색이 예쁘게 나왔어요. 정말 가볍고.예뻐요.\n",
       "90992                                      버틸컬만 교환할수있어서 좋아요\n",
       "143786                                          쓰레기에요 하지마세요\n",
       "Name: reviews, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰 문장 추출\n",
    "sentences = train_data['reviews']\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] 굿 괜찮네요굿배송도빠르게왔네요저렴한지는 잘모르겠지만효과가좋으면괜찮겠네요효과좋겠죠아무튼잘샀어요추천할만햐ㅐ요 [SEP]',\n",
       " '[CLS] 재구매 마트보다 고기가 좋아요 믿고 구매합니다 [SEP]',\n",
       " '[CLS] 약관동의 창이 아무 내용도 없는 하얀화면인데 어떻게 로그인 하라는건지 [SEP]',\n",
       " '[CLS] 조금더 작은 사이즈 있으면 좋겠어요 [SEP]',\n",
       " '[CLS] 처음 구매했는데 좋으네요^^ [SEP]',\n",
       " '[CLS] 잘 먹고 있습니다. 꼼꼼한 포장 감사드립니다. [SEP]',\n",
       " '[CLS] 아직 계약이 안된건가여 요즘 드라마 대세가 인데 넘 아쉽습니다 꼭 나오게 좀 해주셔여 ㅠㅜ [SEP]',\n",
       " '[CLS] 민트색이 예쁘게 나왔어요. 정말 가볍고.예뻐요. [SEP]',\n",
       " '[CLS] 버틸컬만 교환할수있어서 좋아요 [SEP]',\n",
       " '[CLS] 쓰레기에요 하지마세요 [SEP]']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT의 입력 형식에 맞게 변환\n",
    "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라벨 추출\n",
    "labels = train_data['label'].values\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 굿 괜찮네요굿배송도빠르게왔네요저렴한지는 잘모르겠지만효과가좋으면괜찮겠네요효과좋겠죠아무튼잘샀어요추천할만햐ㅐ요 [SEP]\n",
      "['[CLS]', '굿', '괜', '##찮', '##네', '##요', '##굿', '##배', '##송', '##도', '##빠', '##르게', '##왔', '##네', '##요', '##저', '##렴', '##한', '##지는', '[UNK]', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "print (sentences[0])\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   101,   8915,   8904, 119250,  77884,  48549, 118657,  76036,\n",
       "       119057,  12092, 119008,  78131, 119163,  77884,  48549,  48387,\n",
       "       118878,  11102,  32815,    100,    102,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 토큰의 최대 시퀀스 길이\n",
    "MAX_LEN = 128\n",
    "\n",
    "# 토큰을 숫자 인덱스로 변환\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 마스크 초기화\n",
    "attention_masks = []\n",
    "\n",
    "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "print(attention_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   101,   9303,  16439,  49543,  16439, 119022,  48446, 119112,  10892,\n",
      "         28911, 119091,  23811,  10739,  37004,    102,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0])\n",
      "tensor(0)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "tensor([   101,   9995, 118992,  79602,   9495,  12965,  48549,    102,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0])\n",
      "tensor(0)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# 훈련셋과 검증셋으로 분리\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n",
    "                                                                                    labels, \n",
    "                                                                                    random_state=2018, \n",
    "                                                                                    test_size=0.1)\n",
    "\n",
    "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
    "                                                       input_ids,\n",
    "                                                       random_state=2018, \n",
    "                                                       test_size=0.1)\n",
    "\n",
    "# 데이터를 파이토치의 텐서로 변환\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)\t\t\t\t\n",
    "\n",
    "print(train_inputs[0])\n",
    "print(train_labels[0])\n",
    "print(train_masks[0])\n",
    "print(validation_inputs[0])\n",
    "print(validation_labels[0])\n",
    "print(validation_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 사이즈\n",
    "batch_size = 32\n",
    "\n",
    "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
    "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리 - 테스트셋\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203568    댓글 지우네 당신들 앱 실행시키고 나니까 폰이 먹통이야 비싼요금제 써가면서 당신들 ...\n",
       "232565                                     티빙톡은 라이브밖에 없는건가요\n",
       "156534    평소에 백화점에 자주들러 보테가 지갑을 보는데여 백화점 제품하고 아주 동일합니다 기...\n",
       "238961                     와이파이뜨는거괜찮은데 보다가갑자기 앱이종료되고 창이종료되요\n",
       "201059    걍 이번 기회에 사람들 새로 뽑으시죠 일부터 주나 걸린다ㅋㅋㅋ 응대 하시는분들만 고...\n",
       "142075                    4개구입했는데 유효기한이 길지않아요 1년전에 산거보다 짧아요\n",
       "223297            이거 너무 불편해요 이거 같이 볼수도 없게하고 명이상은 같이보게 해주셔야줘\n",
       "192138                            처음 써 봤는데, 적당한 펄감에 지속력 좋네요\n",
       "47983                               너무 맛있습니당 ㅋ 가성비 짱이네요 ㅎㅎㅎ\n",
       "66510                                           재밌어요 ㅋㅋㅋ 무지\n",
       "Name: reviews, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰 문장 추출\n",
    "sentences = test_data['reviews']\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] 댓글 지우네 당신들 앱 실행시키고 나니까 폰이 먹통이야 비싼요금제 써가면서 당신들 앱을 써야돼 타임아웃 같은 문구 띄우지마 안되면 안된다고 얘기하고 공지하라고 영자님아 장난하세요 능력이 안되요 딴생각하지말고 앱안정화나 시키세요 댓글 지우지마 [SEP]',\n",
       " '[CLS] 티빙톡은 라이브밖에 없는건가요 [SEP]',\n",
       " '[CLS] 평소에 백화점에 자주들러 보테가 지갑을 보는데여 백화점 제품하고 아주 동일합니다 기회가된다면 다음에 꼭 또 구매하고싶네여 [SEP]',\n",
       " '[CLS] 와이파이뜨는거괜찮은데 보다가갑자기 앱이종료되고 창이종료되요 [SEP]',\n",
       " '[CLS] 걍 이번 기회에 사람들 새로 뽑으시죠 일부터 주나 걸린다ㅋㅋㅋ 응대 하시는분들만 고생이네요 능력없는 프로그래머들 덕분ㅎㅎ [SEP]',\n",
       " '[CLS] 4개구입했는데 유효기한이 길지않아요 1년전에 산거보다 짧아요 [SEP]',\n",
       " '[CLS] 이거 너무 불편해요 이거 같이 볼수도 없게하고 명이상은 같이보게 해주셔야줘 [SEP]',\n",
       " '[CLS] 처음 써 봤는데, 적당한 펄감에 지속력 좋네요 [SEP]',\n",
       " '[CLS] 너무 맛있습니당 ㅋ 가성비 짱이네요 ㅎㅎㅎ [SEP]',\n",
       " '[CLS] 재밌어요 ㅋㅋㅋ 무지 [SEP]']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT의 입력 형식에 맞게 변환\n",
    "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라벨 추출\n",
    "labels = test_data['label'].values\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 댓글 지우네 당신들 앱 실행시키고 나니까 폰이 먹통이야 비싼요금제 써가면서 당신들 앱을 써야돼 타임아웃 같은 문구 띄우지마 안되면 안된다고 얘기하고 공지하라고 영자님아 장난하세요 능력이 안되요 딴생각하지말고 앱안정화나 시키세요 댓글 지우지마 [SEP]\n",
      "['[CLS]', '댓', '##글', '지', '##우', '##네', '당', '##신', '##들', '앱', '실', '##행', '##시', '##키', '##고', '나', '##니', '##까', '폰', '##이', '먹', '##통', '##이', '##야', '비', '##싼', '##요', '##금', '##제', '써', '##가', '##면서', '당', '##신', '##들', '앱', '##을', '써', '##야', '##돼', '타', '##임', '##아', '##웃', '같은', '문', '##구', '띄', '##우', '##지', '##마', '안', '##되', '##면', '안', '##된다', '##고', '얘', '##기', '##하고', '공', '##지', '##하라', '##고', '영', '##자', '##님', '##아', '장', '##난', '##하', '##세', '##요', '능', '##력이', '안', '##되', '##요', '딴', '##생', '##각', '##하지', '##말', '##고', '앱', '##안', '##정', '##화', '##나', '시', '##키', '##세', '##요', '댓', '##글', '지', '##우', '##지', '##마', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "print (sentences[0])\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   101,   9073, 118663,   9706,  27355,  77884,   9067,  25387,\n",
       "        27023,   9536,   9489,  25549,  14040,  21039,  11664,   8982,\n",
       "        25503, 118671,   9930,  10739,   9266,  43022,  10739,  21711,\n",
       "         9379, 119091,  48549,  40032,  17730,   9502,  11287,  30936,\n",
       "         9067,  25387,  27023,   9536,  10622,   9502,  21711, 118798,\n",
       "         9845,  36240,  16985, 119170,  18589,   9297,  17196,   9154,\n",
       "        27355,  12508,  23811,   9521, 118800,  14867,   9521,  22096,\n",
       "        11664,   9545,  12310,  12453,   8896,  12508, 101656,  11664,\n",
       "         9574,  13764, 108578,  16985,   9657,  33305,  35506,  24982,\n",
       "        48549,   9046,  61964,   9521, 118800,  48549,   9132,  24017,\n",
       "        66540,  23665,  89523,  11664,   9536,  34951,  16605,  18227,\n",
       "        16439,   9485,  21039,  24982,  48549,   9073, 118663,   9706,\n",
       "        27355,  12508,  23811,    102,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 토큰의 최대 시퀀스 길이\n",
    "MAX_LEN = 128\n",
    "\n",
    "# 토큰을 숫자 인덱스로 변환\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 마스크 초기화\n",
    "attention_masks = []\n",
    "\n",
    "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "print(attention_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   101,   9073, 118663,   9706,  27355,  77884,   9067,  25387,  27023,\n",
      "          9536,   9489,  25549,  14040,  21039,  11664,   8982,  25503, 118671,\n",
      "          9930,  10739,   9266,  43022,  10739,  21711,   9379, 119091,  48549,\n",
      "         40032,  17730,   9502,  11287,  30936,   9067,  25387,  27023,   9536,\n",
      "         10622,   9502,  21711, 118798,   9845,  36240,  16985, 119170,  18589,\n",
      "          9297,  17196,   9154,  27355,  12508,  23811,   9521, 118800,  14867,\n",
      "          9521,  22096,  11664,   9545,  12310,  12453,   8896,  12508, 101656,\n",
      "         11664,   9574,  13764, 108578,  16985,   9657,  33305,  35506,  24982,\n",
      "         48549,   9046,  61964,   9521, 118800,  48549,   9132,  24017,  66540,\n",
      "         23665,  89523,  11664,   9536,  34951,  16605,  18227,  16439,   9485,\n",
      "         21039,  24982,  48549,   9073, 118663,   9706,  27355,  12508,  23811,\n",
      "           102,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0])\n",
      "tensor(0)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 파이토치의 텐서로 변환\n",
    "test_inputs = torch.tensor(input_ids)\n",
    "test_labels = torch.tensor(labels)\n",
    "test_masks = torch.tensor(attention_masks)\n",
    "\n",
    "print(test_inputs[0])\n",
    "print(test_labels[0])\n",
    "print(test_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 사이즈\n",
    "batch_size = 32\n",
    "\n",
    "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
    "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# GPU 디바이스 이름 구함\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# GPU 디바이스 이름 검사\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# 디바이스 설정\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분류를 위한 BERT 모델 생성\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 설정\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # 학습률\n",
    "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
    "                )\n",
    "\n",
    "# 에폭수\n",
    "epochs = 4\n",
    "\n",
    "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 계산 함수\n",
    "def flat_accuracy(preds, labels):\n",
    "    \n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  5,128.    Elapsed: 0:02:47.\n",
      "  Batch 1,000  of  5,128.    Elapsed: 0:05:35.\n",
      "  Batch 1,500  of  5,128.    Elapsed: 0:08:23.\n",
      "  Batch 2,000  of  5,128.    Elapsed: 0:11:11.\n",
      "  Batch 2,500  of  5,128.    Elapsed: 0:13:59.\n",
      "  Batch 3,000  of  5,128.    Elapsed: 0:16:47.\n",
      "  Batch 3,500  of  5,128.    Elapsed: 0:19:35.\n",
      "  Batch 4,000  of  5,128.    Elapsed: 0:22:24.\n",
      "  Batch 4,500  of  5,128.    Elapsed: 0:25:12.\n",
      "  Batch 5,000  of  5,128.    Elapsed: 0:28:01.\n",
      "\n",
      "  Average training loss: 0.27\n",
      "  Training epcoh took: 0:28:44\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "  Validation took: 0:01:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  5,128.    Elapsed: 0:03:03.\n",
      "  Batch 1,000  of  5,128.    Elapsed: 0:06:20.\n",
      "  Batch 1,500  of  5,128.    Elapsed: 0:09:13.\n",
      "  Batch 2,000  of  5,128.    Elapsed: 0:12:01.\n",
      "  Batch 2,500  of  5,128.    Elapsed: 0:14:49.\n",
      "  Batch 3,000  of  5,128.    Elapsed: 0:17:37.\n",
      "  Batch 3,500  of  5,128.    Elapsed: 0:20:25.\n",
      "  Batch 4,000  of  5,128.    Elapsed: 0:23:13.\n",
      "  Batch 4,500  of  5,128.    Elapsed: 0:26:01.\n",
      "  Batch 5,000  of  5,128.    Elapsed: 0:28:49.\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:29:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "  Validation took: 0:01:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  5,128.    Elapsed: 0:02:48.\n",
      "  Batch 1,000  of  5,128.    Elapsed: 0:05:36.\n",
      "  Batch 1,500  of  5,128.    Elapsed: 0:08:24.\n",
      "  Batch 2,000  of  5,128.    Elapsed: 0:11:12.\n",
      "  Batch 2,500  of  5,128.    Elapsed: 0:14:00.\n",
      "  Batch 3,000  of  5,128.    Elapsed: 0:16:48.\n",
      "  Batch 3,500  of  5,128.    Elapsed: 0:19:36.\n",
      "  Batch 4,000  of  5,128.    Elapsed: 0:22:24.\n",
      "  Batch 4,500  of  5,128.    Elapsed: 0:25:12.\n",
      "  Batch 5,000  of  5,128.    Elapsed: 0:28:00.\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epcoh took: 0:28:43\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.92\n",
      "  Validation took: 0:01:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  5,128.    Elapsed: 0:02:48.\n",
      "  Batch 1,000  of  5,128.    Elapsed: 0:05:36.\n",
      "  Batch 1,500  of  5,128.    Elapsed: 0:08:24.\n",
      "  Batch 2,000  of  5,128.    Elapsed: 0:11:12.\n",
      "  Batch 2,500  of  5,128.    Elapsed: 0:14:00.\n",
      "  Batch 3,000  of  5,128.    Elapsed: 0:16:48.\n",
      "  Batch 3,500  of  5,128.    Elapsed: 0:19:35.\n",
      "  Batch 4,000  of  5,128.    Elapsed: 0:22:23.\n",
      "  Batch 4,500  of  5,128.    Elapsed: 0:25:11.\n",
      "  Batch 5,000  of  5,128.    Elapsed: 0:27:59.\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:28:42\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.92\n",
      "  Validation took: 0:01:01\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# 재현을 위해 랜덤시드 고정\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# 그래디언트 초기화\n",
    "model.zero_grad()\n",
    "\n",
    "# 에폭만큼 반복\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # 시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    model.train()\n",
    "        \n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward 수행                \n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask, \n",
    "                        labels=b_labels)\n",
    "        \n",
    "        # 로스 구함\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 스케줄러로 학습률 감소\n",
    "        scheduler.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "    # 평균 로스 계산\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    #시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for batch in validation_dataloader:\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():     \n",
    "            # Forward 수행\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트셋 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  1,900.    Elapsed: 0:00:11.\n",
      "  Batch   200  of  1,900.    Elapsed: 0:00:21.\n",
      "  Batch   300  of  1,900.    Elapsed: 0:00:32.\n",
      "  Batch   400  of  1,900.    Elapsed: 0:00:43.\n",
      "  Batch   500  of  1,900.    Elapsed: 0:00:53.\n",
      "  Batch   600  of  1,900.    Elapsed: 0:01:04.\n",
      "  Batch   700  of  1,900.    Elapsed: 0:01:14.\n",
      "  Batch   800  of  1,900.    Elapsed: 0:01:25.\n",
      "  Batch   900  of  1,900.    Elapsed: 0:01:36.\n",
      "  Batch 1,000  of  1,900.    Elapsed: 0:01:46.\n",
      "  Batch 1,100  of  1,900.    Elapsed: 0:01:57.\n",
      "  Batch 1,200  of  1,900.    Elapsed: 0:02:08.\n",
      "  Batch 1,300  of  1,900.    Elapsed: 0:02:18.\n",
      "  Batch 1,400  of  1,900.    Elapsed: 0:02:29.\n",
      "  Batch 1,500  of  1,900.    Elapsed: 0:02:39.\n",
      "  Batch 1,600  of  1,900.    Elapsed: 0:02:50.\n",
      "  Batch 1,700  of  1,900.    Elapsed: 0:03:01.\n",
      "  Batch 1,800  of  1,900.    Elapsed: 0:03:11.\n",
      "\n",
      "Accuracy: 0.92\n",
      "Test took: 0:03:22\n"
     ]
    }
   ],
   "source": [
    "#시작 시간 설정\n",
    "t0 = time.time()\n",
    "\n",
    "# 평가모드로 변경\n",
    "model.eval()\n",
    "\n",
    "# 변수 초기화\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    # 경과 정보 표시\n",
    "    if step % 100 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
    "\n",
    "    # 배치를 GPU에 넣음\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # 배치에서 데이터 추출\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "print(\"\")\n",
    "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 새로운 문장 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 변환\n",
    "def convert_input_data(sentences):\n",
    "\n",
    "    # BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "    # 입력 토큰의 최대 시퀀스 길이\n",
    "    MAX_LEN = 128\n",
    "\n",
    "    # 토큰을 숫자 인덱스로 변환\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    \n",
    "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    # 어텐션 마스크 초기화\n",
    "    attention_masks = []\n",
    "\n",
    "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "\n",
    "    # 데이터를 파이토치의 텐서로 변환\n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return inputs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 테스트\n",
    "def test_sentences(sentences):\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 문장을 입력 데이터로 변환\n",
    "    inputs, masks = convert_input_data(sentences)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "            \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0768989 -0.7515797]]\n",
      "0\n",
      "부정 리뷰입니다.\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['한번 더팅기면 회사 소각시켜도되나요'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))\n",
    "\n",
    "if(np.argmax(logits) == 1):\n",
    "    print(\"긍정 리뷰입니다.\")\n",
    "else:\n",
    "    print(\"부정 리뷰입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.3840263 -3.059722 ]]\n",
      "0\n",
      "부정 리뷰입니다.\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['이거 시간 돌리기 쓰면 화질깨지고 최악이에요'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))\n",
    "\n",
    "if(np.argmax(logits) == 1):\n",
    "    print(\"긍정 리뷰입니다.\")\n",
    "else:\n",
    "    print(\"부정 리뷰입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.1918442  1.2627723]]\n",
      "1\n",
      "긍정 리뷰입니다.\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['넘넘 좋아요 유용합니다'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))\n",
    "\n",
    "if(np.argmax(logits) == 1):\n",
    "    print(\"긍정 리뷰입니다.\")\n",
    "else:\n",
    "    print(\"부정 리뷰입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.8046587  2.037396 ]]\n",
      "1\n",
      "긍정 리뷰입니다.\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['최고의 어플이네요 정말정말 좋습니다'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))\n",
    "\n",
    "if(np.argmax(logits) == 1):\n",
    "    print(\"긍정 리뷰입니다.\")\n",
    "else:\n",
    "    print(\"부정 리뷰입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM분석.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "yj",
   "language": "python",
   "name": "yj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
